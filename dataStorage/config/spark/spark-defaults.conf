spark.master yarn
# spark.sql.warehouse.dir         hdfs://namenode:9000/user/hive/warehouse
spark.submit.deployMode cluster
spark.hadoop.fs.defaultFS hdfs://172.20.0.2:9000

# Configuration pour les exécuteurs
# spark.executor.instances 2           
# spark.executor.cores 2           
# spark.executor.memory 1g        
# spark.driver.memory 1g
# spark.yarn.am.memory 512m

# spark.executor.extraJavaOptions --add-opens=java.base/sun.nio.ch=ALL-UNNAMED
# spark.driver.extraJavaOptions --add-opens=java.base/sun.nio.ch=ALL-UNNAMED

# Configuration principale

# Configuration de la mémoire
spark.executor.memory=1g                        # Mémoire allouée pour les executors
spark.driver.memory=2g                          # Mémoire allouée pour le driver
# spark.memory.fraction=0.6                       # 60% de la mémoire pour les calculs
# spark.memory.storageFraction=0.4                # 40% de la mémoire pour le stockage intermédiaire

# Configuration des cœurs
spark.executor.cores=2                          # Nombre de cœurs pour les executors
spark.driver.cores=2                            # Nombre de cœurs pour le driver

# Configuration des partitions
# spark.default.parallelism=8                     # Nombre de partitions par défaut pour les RDD
# spark.sql.files.maxPartitionBytes=32m           # Taille maximale d'une partition
# Compression
# spark.shuffle.compress=true                     # Compression pour les données de shuffle
# spark.rdd.compress=true                         # Compression pour les RDD intermédiaires

# Garbage Collection (optionnel)
spark.executor.extraJavaOptions=-XX:+UseG1GC    # Utiliser le ramasse-miettes G1 pour l'executor
spark.driver.extraJavaOptions=-XX:+UseG1GC      # Utiliser le ramasse-miettes G1 pour le driver
